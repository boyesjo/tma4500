\section{Quantum NNs versus classical NNs}
\label{sec:qnn-vs-nn}

In order to compare the performance of the QNN and the NN, architectures suited for binary classification with exactly 8 parameters are used, following approach used by \textcite{abbas2021} in \citetitle{abbas2021}.
In their paper, they study the effective dimension of QNNs and NNs, and find that the effective dimension of QNNs is much higher than that of NNs, which they argue leads to better trainability of QNNs.
The goal of this section is to reproduce their results, but also to shed some light on whether the NN used is a fair comparison to the QNN.

\subsection{Data}
The models are tested on Fisher's iris data set \cite{fisher1936}, containing samples of three different species of iris flowers.
There are 50 samples of each species, giving a total of 150 samples, and each sample has four features: sepal length, sepal width, petal length and petal width.
In Fisher's original paper, linear discriminant analysis was used to classify the flowers.
Since then, the data set has become a standard benchmark for statistical classification techniques and machine learning methods like support vector machines.

Like in \cite{abbas2021}, only the two first species are considered, reducing the task to a binary classification problem.
These are linearly separable, so the models should be able to learn to classify them.


\subsection{Quantum NN}
First, the four-dimensional input data is first scaled to have zero mean and unit variance.
Some scaling is necessary for the encoding to work properly, and standardising the data is a natural choice, common in machine learning.
Then, it is encoded into a quantum state a second order angle encoding with $Z$-rotations, discussed in \cref{sec:second_order_angle_encoding}, with two repetitions.
In the Qiskit framework, this is implemented in the \texttt{ZZFeatureMap} class.
This entangles the qubits and embeds them in higher dimensional space.

Next, the state is evolved by the parametrised circuit.
It consists of initial parametrised $Y$-rotations, then full entanglement using controlled not-gates, and lastly final parametrised $Y$-rotations.
The different rotation direction ensures the gates do not commute.
There are in total 8 parameters.
This is implemented in Qiskit as the \texttt{RealAmplitudes} ansatz.

Finally, all four qubits are measured and the parity of the four bit output is interpreted as the prediction of the class label.
\Cref{fig:qnn_vs_nn_models} shows the structure of the QNN and how the parameters are used.

Both exact simulations and noisy simulations were performed.
To model noise, the Qiskit simulator was set to simulate the 27-qubit IBM Montreal architecture, which was the actual hardware used in \cite{abbas2021}.

\begin{figure}
    \centering
    \begin{quantikz}
        \lstick{$\ket{0}$} &
        \gate[wires=4, disable auto height]{{\rotatebox{90}{\texttt{ZZFeatureMap}$(\bm{x})$}}} &
        \gate{R_Y(\theta_1)}
        \gategroup[
            wires=4,
            steps=8,
            style={dashed, rounded corners, inner sep=2pt},
            label style={label position=below, anchor=north, yshift=-0.2cm},
        ]{
            \texttt{RealAmplitudes}$(\bm{\theta})$
        }
        &
        \ctrl{1} &
        \ctrl{2} &
        \ctrl{3} &
        \qw &
        \qw &
        \qw &
        \gate{R_Y(\theta_5)} &
        \meter{}
        \\
        \lstick{$\ket{0}$} &
        \qw &
        \gate{R_Y (\theta_2)} &
        \targ{} &
        \qw &
        \qw &
        \ctrl{1} &
        \ctrl{2} &
        \qw &
        \gate{R_Y(\theta_6)} &
        \meter{}
        \\
        \lstick{$\ket{0}$} &
        \qw &
        \gate{R_Y (\theta_3)} &
        \qw &
        \targ{} &
        \qw &
        \targ{} &
        \qw &
        \ctrl{1} &
        \gate{R_Y(\theta_7)} &
        \meter{}
        \\
        \lstick{$\ket{0}$} &
        \qw &
        \gate{R_Y (\theta_4)} &
        \qw &
        \qw &
        \targ{}&
        \qw &
        \targ{}&
        \targ{}&
        \gate{R_Y(\theta_8)} &
        \meter{}
    \end{quantikz}
    \caption{
        Structure of the QNN used for classification of the iris dataset.
        The first block maps the input data $\bm{x}$ to the quantum state $\ket{\psi(\bm{x})}$ using a second order $Z$ rotation feature map.
        The second block is the variational circuit, parametrised by $\bm{\theta}$, a vector with eight components.
        Finally, all qubits are measured, where the parity is interpreted as the prediction.
    }
    \label{fig:qnn_vs_nn_models}
\end{figure}


\subsection{Classical NN}
The classical neural network was a standard dense feed-forward model.
To make in comparable to the QNN, it used a 4-1-1-1-2 layered structure without biases, giving a total of 8 parameters.
The activation functions were leaky ReLUs,
\begin{equation}
    \text{LeakyReLU}(x) = \begin{cases}
        x     & x \geq 0 \\
        0.01x & x < 0
    \end{cases},
\end{equation}
and the output layer used a softmax activation function.
Whether such an architecture makes sense is arguable, and it was likely made so mainly to ensure that the number of parameters would be the same as the QNN.


\subsection{Implementation and training}
Both models were implemented using PyTorch, with code partly taken from the original paper\footnote{Available at \url{https://github.com/amyami187/effective_dimension}.}.
The QNN was adapted to use Qiskit's PyTorch interface.
Consequently, the models could be trained in the exact same manner, using the Adam optimiser with a learning rate of 0.1 and cross-entropy loss.
The classical and noiseless models were trained for 100 epochs, while the noisy model was only trained for 10, as simulating the noise severely impacted training time.

\subsection{Results}
For validation, 10-fold cross-validation was used.
That is, the dataset was split into 10 equal parts (folds).
Each fold us used as the validation set once, their accuracies being recorded during the training with the other nine folds.
The mean accuracy over the 10 folds was used for the final performance metric, shown in \cref{fig:iris_training}.

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                width=0.8\textwidth,
                height=0.5\textwidth,
                xlabel={Iteration},
                ylabel={Mean out-of-fold accuracy},
                grid = major,
                legend pos=south east,
                legend cell align={left},
            ]
            \addplot[mark=none, color=red] table[x expr=\coordindex+1, y index=3, col sep=comma] {../code/iris/results/mean.csv};
            \addplot[mark=none, color=blue] table[x expr=\coordindex+1, y index=2, col sep=comma] {../code/iris/results/mean.csv};
            \addplot[mark=none, color=green] table[x expr=\coordindex+1, y index=1, col sep=comma] {../code/iris/results/mean.csv};
            \legend{
                Noisy QNN,
                Exact QNN,
                Classical NN
            }
        \end{axis}
    \end{tikzpicture}
    \caption{
        Mean accuracies during training for the iris dataset.
        Ten-fold cross-validation was used, with the mean out-of-fold accuracy being used as the final performance metric.
        All models have 8 parameters and are trained using the Adam optimiser with a learning rate of 0.1, using cross-entropy as the loss function.
        Due to the computational cost, the noisy (simulated IBM Montreal backend) QNN was only trained for ten epochs.
    }
    \label{fig:iris_training}
\end{figure}


As in the original paper, the QNN converges much quicker and more consistently, with an out-of-fold accuracy of 100\% for all ten folds.
The classical network, on the other hand, requires more iterations to converge and does not always do so.
In some cases, the model did not converge, only predicting one class, which is why the out-of-fold accuracy was not 100\% for all folds.
This is in line with the original paper, underlining the potential advantage of quantum neural networks.

Why parity was chosen as output interpretation is not clear, other than being cited as a \enquote{standard in practice}.
However, it is not the only possible interpretation, and a perhaps more intuitive one would be to use the sign of just one of the qubits.
Doing so effectively ignores three of the qubits, giving a parameter count of five.
Five is coincidentally also the parameter choice of a logistic regression scheme, which could be a more natural choice for a classical classification algorithm than the neural network whose architecture appears mostly based on the goal of having eight parameters.

Looking at the testing visualised in \cref{fig:iris_training_lr} reveals that parity indeed performs better than the sign of a single qubit, though not by much.
The bigger revelation is the performance of logistic regression, which greatly outperforms the neural network, and while slightly slower to converge than the quantum models, does approach an overall smaller loss value.

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                width=0.8\textwidth,
                height=0.5\textwidth,
                xlabel={Iteration},
                ylabel={Mean cross-entropy},
                grid = major,
                legend pos=north east,
                legend cell align={left},
            ]
            \addplot[mark=none, color=red] table[x = epoch, y=loss, col sep=comma] {../code/iris/results_5/QNN_parity.csv};
            \addplot[mark=none, color=blue] table[x = epoch, y=loss, col sep=comma] {../code/iris/results_5/QNN_last.csv};
            \addplot[mark=none, color=green] table[x = epoch, y=loss, col sep=comma] {../code/iris/results_5/NN.csv};
            \addplot[mark=none, color=orange] table[x = epoch, y=loss, col sep=comma] {../code/iris/results_5/LogReg.csv};
            \legend{
                QNN (parity),
                QNN (sign),
                Classical NN,
                Logistic regression,
            }
        \end{axis}
    \end{tikzpicture}
    \caption{
        Cross-entropy loss during training for the iris dataset.
        The QNN with parity interpretation has eight parameters, while the QNN with sign interpretation has effectively five.
        The classical neural network has eight and the logistic regression has five parameters.
    }
    \label{fig:iris_training_lr}
\end{figure}
